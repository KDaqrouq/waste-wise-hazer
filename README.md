# Waste Wise Hazer - AI-Powered Food Waste Detection System

A comprehensive food waste detection system that uses computer vision and machine learning to identify and count different types of fruits and vegetables in images. The system includes both a **mock enterprise dashboard** for demonstration purposes and a **fully functional food detection engine** with real AI processing.

## ğŸš€ Features

### âœ… **Real Food Detection System** (Fully Functional)
- **AI-Powered Detection**: YOLOv8-based object detection trained on fruit/vegetable datasets
- **Real-time Analysis**: Instant image processing with bounding boxes and confidence scores
- **Multi-Input Support**: File upload, drag-and-drop, and live camera capture
- **Automatic Classification**: 11 food categories (apple, tangerine, pear, watermelon, durian, lemon, grape, pineapple, dragon fruit, korean melon, cantaloupe)
- **Live Camera Integration**: Direct webcam access with automatic image capture and processing
- **File Management**: Organized storage with dedicated folders for uploads and camera captures
- **Backend API**: Flask server with RESTful endpoints for image processing

### ğŸ­ **Mock Enterprise Dashboard** (Demonstration Only)
- **UAE Network Map**: Simulated map view of 12+ locations across 5 Emirates (mock data)
- **Interactive Pins**: Color-coded locations (green=low, yellow=medium, red=high waste)
- **Government Badges**: UAE National Food Security Strategy 2051, Ne'ma Initiative, UN SDGs
- **Analytics Charts**: Mock waste data with red-highlighted high-waste categories
- **Alert System**: Simulated notifications to food banks, delivery partners, and kitchens
- **Impact Screens**: Mock calculations showing kg saved and AED cost savings
- **Network Statistics**: Simulated real-time monitoring data

## ğŸ” **What's Real vs Mock**

### **Real Components** (Actual AI Processing):
- âœ… Food Detection Page - Real YOLOv8 model processing
- âœ… Camera Capture - Live webcam integration
- âœ… Image Upload - File processing and classification
- âœ… Backend API - Flask server with actual ML inference
- âœ… Detection Results - Real bounding boxes and confidence scores
- âœ… File Storage - Actual image saving and organization

### **Mock Components** (Demonstration Only):
- ğŸ­ UAE Network Map - Simulated locations and data
- ğŸ­ Dashboard Analytics - Mock charts and statistics
- ğŸ­ Alert Notifications - Simulated alerts (no real notifications sent)
- ğŸ­ Impact Calculations - Mock savings calculations
- ğŸ­ Government Badges - Visual elements for presentation
- ğŸ­ Network Statistics - Simulated monitoring data

## ğŸ—ï¸ Architecture

```
Frontend (React + TypeScript + Vite) â†â†’ Backend (Flask + YOLO) â†â†’ Trained Model
     â†“                                    â†“                        â†“
Multi-Input Interface                API Processing           Object Detection
     â†“                                    â†“                        â†“
â€¢ File Upload                        Model Inference          Bounding Boxes
â€¢ Drag & Drop                        Image Annotation         Class Counts
â€¢ Camera Capture                     Alert Processing         Impact Calculation
     â†“                                    â†“                        â†“
Interactive Dashboard               JSON Response           Real-time Alerts
     â†“                                    â†“                        â†“
â€¢ Network Map                       File Management         Notification System
â€¢ Analytics Charts                  Database Storage        Cost Savings Tracking
â€¢ Alert Management                  Multi-location Support  Government Reporting
```

## ğŸ› ï¸ Tech Stack

### **Frontend**
- **React 18** - Modern UI framework with hooks and functional components
- **TypeScript** - Type-safe JavaScript development
- **Vite** - Fast build tool and development server
- **Tailwind CSS** - Utility-first CSS framework
- **shadcn/ui** - Modern component library with Radix UI primitives
- **Recharts** - Data visualization and charting library
- **React Router** - Client-side routing
- **Lucide React** - Icon library

### **Backend**
- **Python 3.8+** - Core programming language
- **Flask** - Lightweight web framework
- **Flask-CORS** - Cross-origin resource sharing
- **YOLOv8 (Ultralytics)** - State-of-the-art object detection model
- **OpenCV** - Computer vision and image processing
- **PyTorch** - Deep learning framework
- **Pillow (PIL)** - Python imaging library
- **NumPy** - Numerical computing

### **AI/ML & Computer Vision**
- **YOLOv8** - Custom-trained object detection model
- **Custom Dataset** - Fruit/vegetable detection training data
- **Roboflow** - Dataset management and augmentation
- **OpenCV** - Image preprocessing and annotation
- **PyTorch** - Model training and inference

### **Development Tools**
- **Git** - Version control
- **ESLint** - Code linting and formatting
- **PostCSS** - CSS processing
- **Autoprefixer** - CSS vendor prefixing

## ğŸ“‹ Prerequisites

- **Node.js** (v18 or higher)
- **Python** (v3.8 or higher)
- **Git**

## ğŸ› ï¸ Installation & Setup

### 1. Frontend Setup

```bash
# Clone the repository
git clone <your-repo-url>
cd waste-wise-hazer

# Install dependencies
npm install

# Start development server
npm run dev
```

The frontend will be available at `http://localhost:8080`

### 2. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Run setup script (automatically installs dependencies)
python setup.py

# Or manually install requirements
pip install -r requirements.txt

# Start the Flask server
python app.py
```

The backend API will be available at `http://localhost:5000`

### 3. Model Training (Optional)

If you want to train your own model:

```bash
cd backend

# Run the training pipeline
python train_model.py
```

This will:
- Install training dependencies
- Download the fruit dataset from Roboflow
- Train a YOLOv8 model for 50 epochs
- Test the model and copy it to production

## ğŸ¯ Usage

### **Real Food Detection System**

1. Navigate to `http://localhost:8080`
2. Click "Food Detection" in the header
3. **Upload an image** by:
   - Dragging & dropping files
   - Clicking "Choose File" 
   - Using "Take Photo" for live camera capture
4. Click "Analyze Image" to run **real AI detection**
5. View **actual results** with:
   - Real detection counts per food category
   - Annotated image with bounding boxes
   - Confidence scores for each detection
   - Individual detection details

### **Mock Dashboard** (Demonstration Only)

1. Navigate to `http://localhost:8080` (main page)
2. View the **simulated UAE Network Map** with mock locations
3. See **mock analytics charts** with sample waste data
4. Interact with **simulated alert system** (no real notifications sent)
5. Explore **mock impact calculations** and government alignment badges

### API Endpoints

- `POST /api/predict` - Upload image and get detection results
- `POST /api/camera-capture` - Capture from camera and process automatically
- `GET /api/health` - Health check and model status
- `GET /api/classes` - Get available class names

## ğŸ”§ Configuration

### Model Path
Update the model path in `backend/app.py`:
```python
MODEL_PATH = 'models/best.pt'  # Path to your trained model
```

### Class Names
Modify the class names in `backend/app.py` to match your training data:
```python
CLASS_NAMES = [
    "Apple", "Orange", "Banana", "Grape", "Strawberry",
    "Peach", "Pear", "Kiwi", "Pineapple", "Mango"
]
```

### API Settings
Adjust server settings in `backend/app.py`:
```python
app.run(host='0.0.0.0', port=5000, debug=True)
```

## ğŸ“Š Training Your Own Model

### 1. Dataset Preparation
- Use Roboflow for easy dataset management
- Or manually organize in Pascal VOC/COCO format
- Ensure proper labeling with bounding boxes

### 2. Training Configuration
```python
model.train(
    data="datasets/fruit-object-detection/data.yaml",
    epochs=50,
    imgsz=640,
    batch=16,
    patience=10
)
```

### 3. Model Evaluation
- Check training metrics in `runs/detect/fruit-detection/`
- Validate on test set
- Adjust hyperparameters as needed

## ğŸš¨ Troubleshooting

### Common Issues

1. **Model not loading**
   - Check if `models/best.pt` exists
   - Verify model file integrity
   - Check Python dependencies

2. **CUDA/GPU issues**
   - Install PyTorch with CUDA support
   - Or use CPU-only version for testing

3. **Frontend can't connect to backend**
   - Ensure backend is running on port 5000
   - Check CORS settings
   - Verify network connectivity

4. **Image upload fails**
   - Check file size limits
   - Verify image format (JPEG, PNG)
   - Check backend logs for errors

### Debug Mode

Enable debug logging in the backend:
```python
app.run(debug=True, host='0.0.0.0', port=5000)
```

## ğŸ“ Project Structure

```
waste-wise-hazer/
â”œâ”€â”€ src/                          # Frontend React code
â”‚   â”œâ”€â”€ components/              # UI components
â”‚   â”‚   â”œâ”€â”€ CameraCapture.tsx   # Camera integration
â”‚   â”‚   â”œâ”€â”€ FoodAlert.tsx       # Alert system
â”‚   â”‚   â”œâ”€â”€ FoodWasteChart.tsx  # Analytics charts
â”‚   â”‚   â”œâ”€â”€ LocationMap.tsx     # UAE network map
â”‚   â”‚   â”œâ”€â”€ ImpactScreen.tsx    # Impact tracking
â”‚   â”‚   â””â”€â”€ ui/                 # shadcn/ui components
â”‚   â”œâ”€â”€ pages/                   # Page components
â”‚   â”‚   â”œâ”€â”€ Index.tsx           # Main dashboard
â”‚   â”‚   â””â”€â”€ FoodDetection.tsx   # Food detection page
â”‚   â””â”€â”€ App.tsx                 # Main app component
â”œâ”€â”€ backend/                     # Python backend
â”‚   â”œâ”€â”€ app.py                  # Flask API server
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ setup.py               # Setup script
â”‚   â”œâ”€â”€ train_model.py         # Training pipeline
â”‚   â”œâ”€â”€ models/                 # Trained models
â”‚   â”œâ”€â”€ uploads/                # Temporary uploads
â”‚   â”œâ”€â”€ camera_captures/        # Camera images
â”‚   â””â”€â”€ annotated/              # Annotated images
â”œâ”€â”€ package.json                # Frontend dependencies
â”œâ”€â”€ CAMERA_CAPTURE_FEATURE.md   # Camera feature docs
â””â”€â”€ README.md                   # This file
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- [Ultralytics](https://github.com/ultralytics/ultralytics) for YOLOv8
- [Roboflow](https://roboflow.com/) for dataset management
- [shadcn/ui](https://ui.shadcn.com/) for UI components

## ğŸ“ Support

For questions or issues:
1. Check the troubleshooting section
2. Review backend logs
3. Open an issue on GitHub
4. Contact the development team

---

**Happy detecting! ğŸğŸŒğŸ‡**
